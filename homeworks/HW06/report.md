# HW06 – Report

> Файл: `homeworks/HW06/report.md`  

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target` (бинарная классификация)
  Доли классов:   
  0 ≈ 0.74   
  1 ≈ 0.26    
- Признаки: все признаки числовые (столбец id - столбец идентификаторов строк)

## 2. Protocol

- Разбиение: train/test (доли: 0.25 test и 0.75 train, `random_state`=42)
- Подбор CV на train: 5 фолдов, подбиралась обратная сила регуляризации для логистической регрессии; для decision tree - максимальная глубина,  минимум объектов в листе, штраф за сложность; для ансамбля деревьев - максимальная глубина, минимум объектов в листе, количество признаков для каждого split`а; для AdaBoost - силу вклада каждой итерации и количество итераций
- Метрики: accuracy, F1, ROC-AUC (для всех моделей)
  ```yaml
  [{'accuracy': 0.7373333333333333,
  'f1': 0.0,
  'roc_auc': 0.5,
  'model': 'Dummy(most_frequent)'},
  {'accuracy': 0.8162222222222222,
  'f1': 0.5717244950802693,
  'roc_auc': 0.8008935009673942,
  'model': 'LogReg(scaled)'},
  {'accuracy': 0.8186666666666667,
  'f1': 0.6190476190476191,
  'roc_auc': 0.8317013337494608,
  'model': 'DecisionTree'},
  {'accuracy': 0.8935555555555555,
  'f1': 0.7627538385339276,
  'roc_auc': 0.9303352528228838,
  'model': 'RandomForest'},
  {'accuracy': 0.8355555555555556,
  'f1': 0.6092925026399155,
  'roc_auc': 0.8388961048233039,
  'model': 'AdaBoost'},
  {'accuracy': 0.9128888888888889,
  'f1': 0.8234234234234235,
  'roc_auc': 0.9329206226815941,
  'model': 'Stacking'}]
  ```  
  Данные метрики в целом обязательны, так как помимо одной лишь доли правильных ответов нужна как минимум еще одна метрика, так как присутствует достаточно сильный дисбаланс классов. В данном случае используется ROC-AUC и f1. 

## 3. Models

Сравнивались следующие модели

- DummyClassifier (baseline)
- LogisticRegression (baseline из S05)
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` + `ccp_alpha`)
- RandomForestClassifier
- AdaBoost 
- StackingClassifier (с CV-логикой)

Подбиралась обратная сила регуляризации для логистической регрессии; для decision tree - максимальная глубина,  минимум объектов в листе, штраф за сложность; для ансамбля деревьев - максимальная глубина, минимум объектов в листе, количество признаков для каждого split`а; для AdaBoost - силу вклада каждой итерации и количество итераций

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
  | accuracy | f1 | roc_auc | model |
  |----------|----|---------|-------|
  |0.912889 |0.823423|0.932921|Stacking|
  |0.893556|0.762754|0.930335|RandomForest|
  |0.835556|0.609293|0.838896|AdaBoost|
  |0.818667|0.619048|0.831701|DecisionTree|
  |0.816222|0.571724|0.800894|LogReg(scaled)|
  |0.737333|0.000000|0.500000|Dummy(most_frequent)|

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение

  *Лучшей* моделью по метрикам (по всем) является модель StackingClassifier. Не удивительно, что для данного датасета она является лучшей, поскольку она комбинирует несколько базовых моделей вместе с метамоделью. По принципу "больше - лучше", т. к. Разные модели по-разному ошибаются.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей)
  Поменяв RANDOM_STATE для одной из моделей:
  ```json
  'RS_DecisionTree(0)': {
  'best_cv_roc_auc': 0.826811129632004
  },
  'RS_DecisionTree(1)': {
  'best_cv_roc_auc': 0.8266257396648813
  },
  'RS_DecisionTree(2)': {
  'best_cv_roc_auc': 0.8272213678053356
  },
  'RS_DecisionTree(3)': {
  'best_cv_roc_auc': 0.826674690550354
  },
  'RS_DecisionTree(4)': {
  'best_cv_roc_auc': 0.8265148032153153
  }
  ```
  Вывод: изменение RANDOM_STATE действительно влияет на качество модели, хоть и менее чем на 1%.
- Ошибки: confusion matrix для лучшей модели + комментарий
  Для лучшей модели confusion matrix следующая:
  
  |3194 | 124|
  |-----|----|
  |268|   914|

Большие доли TP и TN, в сравнении значительно малые доли FN, FP - что показывает высокое качество модели.
  
- Интерпретация: permutation importance (top-15) + выводы
![permutation_importance](https://github.com/x446688/aie/blob/main/homeworks/HW06/artifacts/figures/PERMUTATION_IMPORTANCE_BEST.png?raw=true)
  Самое большое влияние на модель оказывает f16 с значительным отрывом от других признаков.  

## 6. Conclusion

Деревья решений являются моделью классификации, работающей по принципу выполнения ветвлений классификации, сужая подмножества данных. Главная проблема обычных DecisionTree является проблема переобучения. Из-за большого количества ветвлений при обучении модели свойственно хуже показывать себя на тестовой выборке. Для решения этих проблем существуют модели RandomForest, Boosting-модели и StackingClassifier. Ансамбли деревьев работают по принципу "больше деревьев - лучше", но Boosting, RandomForest и Stacking работают по разному, где Boosting - строит ансамбль деревьев последовательно, RandomForest (bagging + случайность по признакам) на каждом различении дерева рассматривает случайное подмножество признаков и строит много моделей на bootstrap-выборках (полученные их исходной выборки с помощью случайного выбора с возвращением) и агрегируют ответы, а Stacking - комбинирует разные модели (базовые модели, на основе которых обучается метамодель, учащаяся комбинировать их). Честный ML-эксперимент позволяет построить минимальную "модель" эксперимента, где выполняются все необходимые условия для сравнения моделей и подсчета необходимых метрик, а также сохранения дополнительных артефактов. Данный эксперимент позволяет создать шаблон для работы с разными моделями при дальнейшем выполнении поставленных задач.